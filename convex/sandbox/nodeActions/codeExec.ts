"use node";

/**
 * Code Execution Action (with Streaming Support)
 *
 * Executes TypeScript code generated by the LLM.
 * This is the core of the code execution model - instead of JSON tool calls,
 * the agent writes code that imports from ksa/ and we execute it.
 *
 * Streaming: Output chunks are forwarded to cloud via fire-and-forget
 * for real-time visibility during long-running executions.
 */

import { internalAction } from "../_generated/server";
import { v } from "convex/values";

// Execution limits
const MAX_TIMEOUT_MS = 120_000; // 2 minutes
const MAX_OUTPUT_LENGTH = 50_000; // 50KB

// Chunk size for streaming (balance between latency and overhead)
const STREAM_CHUNK_INTERVAL_MS = 100; // Batch output every 100ms

/**
 * Execute TypeScript code in the sandbox with streaming output.
 *
 * The code can import from /home/user/ksa/ to use available capabilities.
 * Output is captured and optionally streamed to the cloud.
 */
export const execute = internalAction({
  args: {
    code: v.string(),
    timeoutMs: v.optional(v.number()),
    env: v.optional(v.object({
      CONVEX_URL: v.optional(v.string()),
      GATEWAY_URL: v.optional(v.string()),
      LOCAL_CONVEX_URL: v.optional(v.string()),
      SANDBOX_JWT: v.optional(v.string()),
      CARD_ID: v.optional(v.string()),
      THREAD_ID: v.optional(v.string()),
    })),
    // Streaming configuration
    streamConfig: v.optional(v.object({
      sessionId: v.optional(v.string()),
      stepId: v.optional(v.string()),
      cloudUrl: v.optional(v.string()),
    })),
  },
  handler: async (_ctx, args): Promise<{
    success: boolean;
    output: string;
    error?: string;
    exitCode: number;
    streamedChunks?: number; // Track how many chunks were streamed
  }> => {
    // Dynamic imports for Node.js modules (required for Convex bundling)
    const { spawn } = await import("child_process");
    const fs = await import("fs/promises");
    const crypto = await import("crypto");

    const timeout = Math.min(args.timeoutMs || 60_000, MAX_TIMEOUT_MS);

    // Generate unique filename for this execution
    // IMPORTANT: Write to /home/user/ so relative imports like './ksa/beads' resolve correctly
    const hash = crypto.createHash("md5").update(args.code).digest("hex").slice(0, 8);
    const filename = `/home/user/agent_exec_${Date.now()}_${hash}.ts`;

    // Streaming state
    let streamBuffer = "";
    let streamedChunks = 0;
    let streamInterval: NodeJS.Timeout | null = null;

    // Fire-and-forget stream chunk to cloud
    const flushStreamBuffer = () => {
      if (!streamBuffer || !args.streamConfig?.cloudUrl) return;

      const chunk = streamBuffer;
      streamBuffer = "";
      streamedChunks++;

      // Non-blocking POST to cloud
      fetch(`${args.streamConfig.cloudUrl}/agent/stream`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${args.env?.SANDBOX_JWT || ""}`,
        },
        body: JSON.stringify({
          sessionId: args.streamConfig.sessionId,
          stepId: args.streamConfig.stepId,
          chunk,
          chunkIndex: streamedChunks,
          timestamp: Date.now(),
        }),
      }).catch(() => {
        // Fire-and-forget - ignore errors
      });
    };

    try {
      // Write code to temp file
      await fs.writeFile(filename, args.code, "utf-8");

      // Execute with bun using spawn (for streaming)
      const bunPath = "/home/user/.bun/bin/bun";
      const proc = spawn(bunPath, ["run", filename], {
        cwd: "/home/user/workspace",
        env: {
          ...process.env,
          PATH: "/home/user/.bun/bin:/usr/local/bin:/usr/bin:/bin",
          HOME: "/home/user",
          NODE_PATH: "/home/user",
          ...(args.env?.CONVEX_URL && { CONVEX_URL: args.env.CONVEX_URL }),
          ...(args.env?.GATEWAY_URL && { GATEWAY_URL: args.env.GATEWAY_URL }),
          ...(args.env?.SANDBOX_JWT && { SANDBOX_JWT: args.env.SANDBOX_JWT }),
          ...(args.env?.CARD_ID && { CARD_ID: args.env.CARD_ID }),
          ...(args.env?.THREAD_ID && { THREAD_ID: args.env.THREAD_ID }),
        },
      });

      // Collect output
      let stdout = "";
      let stderr = "";

      // Start streaming interval if configured
      if (args.streamConfig?.cloudUrl) {
        streamInterval = setInterval(flushStreamBuffer, STREAM_CHUNK_INTERVAL_MS);
      }

      // Handle stdout
      proc.stdout?.on("data", (data: Buffer) => {
        const text = data.toString();
        stdout += text;

        // Add to stream buffer if streaming enabled
        if (args.streamConfig?.cloudUrl) {
          streamBuffer += text;
        }
      });

      // Handle stderr
      proc.stderr?.on("data", (data: Buffer) => {
        const text = data.toString();
        stderr += text;

        // Add to stream buffer if streaming enabled
        if (args.streamConfig?.cloudUrl) {
          streamBuffer += `[stderr] ${text}`;
        }
      });

      // Wait for process to complete with timeout
      const result = await new Promise<{ success: boolean; exitCode: number; error?: string }>((resolve) => {
        let resolved = false;

        // Timeout handler
        const timeoutId = setTimeout(() => {
          if (!resolved) {
            resolved = true;
            proc.kill("SIGTERM");
            resolve({
              success: false,
              exitCode: 124,
              error: `Execution timed out after ${timeout}ms`,
            });
          }
        }, timeout);

        // Normal completion
        proc.on("close", (code) => {
          if (!resolved) {
            resolved = true;
            clearTimeout(timeoutId);
            resolve({
              success: code === 0,
              exitCode: code ?? 1,
              error: code !== 0 ? `Process exited with code ${code}` : undefined,
            });
          }
        });

        // Error handler
        proc.on("error", (err) => {
          if (!resolved) {
            resolved = true;
            clearTimeout(timeoutId);
            resolve({
              success: false,
              exitCode: 1,
              error: err.message,
            });
          }
        });
      });

      // Stop streaming interval and flush remaining buffer
      if (streamInterval) {
        clearInterval(streamInterval);
        flushStreamBuffer();
      }

      // Combine and truncate output
      let output = stdout || "";
      if (stderr) {
        output += stderr ? `\n[stderr]\n${stderr}` : "";
      }
      if (output.length > MAX_OUTPUT_LENGTH) {
        output = output.slice(0, MAX_OUTPUT_LENGTH) + "\n... (output truncated)";
      }

      return {
        success: result.success,
        output: output.trim(),
        error: result.error,
        exitCode: result.exitCode,
        streamedChunks: args.streamConfig?.cloudUrl ? streamedChunks : undefined,
      };
    } catch (error: unknown) {
      // Stop streaming on error
      if (streamInterval) {
        clearInterval(streamInterval);
      }

      const err = error as { message?: string };
      const message = err.message || String(error);

      return {
        success: false,
        output: "",
        error: message,
        exitCode: 1,
        streamedChunks: args.streamConfig?.cloudUrl ? streamedChunks : undefined,
      };
    } finally {
      // Clean up temp file
      try {
        await fs.unlink(filename);
      } catch {
        // Ignore cleanup errors
      }
    }
  },
});
